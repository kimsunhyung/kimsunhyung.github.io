<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>0704 | 손햄의 개발 이야기</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="확률적 경사 하강법 (단독적으로 사용되지 않음) 점진적 학습 (step, 보폭) 학습률 xgboost,lightgbm, 딥러닝(이미지 분류, 자연어 처리, 옵티마이저)  샘플 신경망 이미지 데이터, 자연어 자율주행 한꺼번에 다 모델을 학습 어려움 샘플링, 배치, 에포크, 오차(&#x3D;손실&#x3D;loss)가 가장 작은 지점을 찾아야 함   결론적으로">
<meta property="og:type" content="article">
<meta property="og:title" content="0704">
<meta property="og:url" content="https://kimsunhyung.github.io/2022/07/04/0704/index.html">
<meta property="og:site_name" content="손햄의 개발 이야기">
<meta property="og:description" content="확률적 경사 하강법 (단독적으로 사용되지 않음) 점진적 학습 (step, 보폭) 학습률 xgboost,lightgbm, 딥러닝(이미지 분류, 자연어 처리, 옵티마이저)  샘플 신경망 이미지 데이터, 자연어 자율주행 한꺼번에 다 모델을 학습 어려움 샘플링, 배치, 에포크, 오차(&#x3D;손실&#x3D;loss)가 가장 작은 지점을 찾아야 함   결론적으로">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://kimsunhyung.github.io/images/0704/output_17_0.png">
<meta property="og:image" content="https://kimsunhyung.github.io/images/0704/output_28_1.png">
<meta property="og:image" content="https://kimsunhyung.github.io/images/0704/output_29_0.png">
<meta property="og:image" content="https://kimsunhyung.github.io/images/0704/output_32_0.png">
<meta property="article:published_time" content="2022-07-04T00:00:00.000Z">
<meta property="article:modified_time" content="2022-07-04T08:06:51.989Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kimsunhyung.github.io/images/0704/output_17_0.png">
  
    <link rel="alternate" href="/atom.xml" title="손햄의 개발 이야기" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">손햄의 개발 이야기</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://kimsunhyung.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-0704" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/07/04/0704/" class="article-date">
  <time class="dt-published" datetime="2022-07-04T00:00:00.000Z" itemprop="datePublished">2022-07-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      0704
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="확률적-경사-하강법-단독적으로-사용되지-않음"><a href="#확률적-경사-하강법-단독적으로-사용되지-않음" class="headerlink" title="확률적 경사 하강법 (단독적으로 사용되지 않음)"></a>확률적 경사 하강법 (단독적으로 사용되지 않음)</h2><ul>
<li>점진적 학습 (step, 보폭)</li>
<li>학습률</li>
<li>xgboost,lightgbm, 딥러닝(이미지 분류, 자연어 처리, 옵티마이저)</li>
</ul>
<h3 id="샘플"><a href="#샘플" class="headerlink" title="샘플"></a>샘플</h3><ul>
<li>신경망 이미지 데이터, 자연어</li>
<li>자율주행</li>
<li>한꺼번에 다 모델을 학습 어려움<ul>
<li>샘플링, 배치, 에포크, 오차(&#x3D;손실&#x3D;loss)가 가장 작은 지점을 찾아야 함</li>
</ul>
</li>
<li>결론적으로 확률적 경사 하강법</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 손실함수</span></span><br><span class="line"><span class="comment">### 로지스틱 손실 함수</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">fish = pd.read_csv(<span class="string">&quot;http://bit.ly/fish_csv_data&quot;</span>)</span><br><span class="line">fish.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 159 entries, 0 to 158
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Species   159 non-null    object 
 1   Weight    159 non-null    float64
 2   Length    159 non-null    float64
 3   Diagonal  159 non-null    float64
 4   Height    159 non-null    float64
 5   Width     159 non-null    float64
dtypes: float64(5), object(1)
memory usage: 7.6+ KB
</code></pre>
<ul>
<li>입력 데이터와 타깃데이터 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Length&#x27;</span>, <span class="string">&#x27;Diagonal&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Width&#x27;</span>]].to_numpy()</span><br><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br><span class="line"></span><br><span class="line">fish_input.shape, fish_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((159, 5), (159,))
</code></pre>
<h3 id="훈련세트와-테스트-데이터-분리"><a href="#훈련세트와-테스트-데이터-분리" class="headerlink" title="훈련세트와 테스트 데이터 분리"></a>훈련세트와 테스트 데이터 분리</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    </span><br><span class="line">    fish_input, fish_target, random_state = <span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled=ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<h3 id="모델링"><a href="#모델링" class="headerlink" title="모델링"></a>모델링</h3><ul>
<li>확률적 경사 하강법</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br></pre></td></tr></table></figure>

<h3 id="xgboost-lighgbm-코드"><a href="#xgboost-lighgbm-코드" class="headerlink" title="xgboost, lighgbm 코드"></a>xgboost, lighgbm 코드</h3><ul>
<li>train-loss, train-accuary, test-loss, test-accu</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">sc = SGDClassifier(loss = <span class="string">&#x27;log&#x27;</span>, max_iter = <span class="number">10</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled,test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.773109243697479
0.775


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
</code></pre>
<ul>
<li>partal_fit()메서그 사용하면 추가학습</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sc.partial_fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8151260504201681
0.85
</code></pre>
<h3 id="에포크와-과대-x2F-과소-적합"><a href="#에포크와-과대-x2F-과소-적합" class="headerlink" title="에포크와 과대&#x2F; 과소 적합"></a>에포크와 과대&#x2F; 과소 적합</h3><ul>
<li>에포크 숫자가 적으면, 덜학습</li>
<li>early_stopping<ul>
<li>에포크 숫자를 1000, 손실 10, 9, 8, 3</li>
<li>3에 도달한 시점이 150</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sc = SGDClassifier(loss =<span class="string">&#x27;log&#x27;</span>, random_state= <span class="number">42</span>)</span><br><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line"></span><br><span class="line">classes = np.unique(train_target)</span><br><span class="line"><span class="comment"># 300번 에포크 훈련 반복</span></span><br><span class="line"><span class="comment"># 훈련할때마다, train_score, test_score 추가</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">300</span>):</span><br><span class="line">  sc.partial_fit(train_scaled, train_target,classes=classes)</span><br><span class="line">  train_score.append(sc.score(train_scaled,train_target))</span><br><span class="line">  test_score.append(sc.score(test_scaled,test_target))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.plot(train_score)</span><br><span class="line">plt.plot(test_score)</span><br><span class="line">plt.legend([<span class="string">&quot;train&quot;</span>,<span class="string">&quot;test&quot;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0704/output_17_0.png" alt="png"></p>
<h2 id="결정트리"><a href="#결정트리" class="headerlink" title="결정트리"></a>결정트리</h2><ul>
<li>wine 데이터 가져오</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;http://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(wine.head())</span><br><span class="line">wine.info()</span><br><span class="line">wine.describe()</span><br></pre></td></tr></table></figure>

<pre><code>   alcohol  sugar    pH  class
0      9.4    1.9  3.51    0.0
1      9.8    2.6  3.20    0.0
2      9.8    2.3  3.26    0.0
3      9.8    1.9  3.16    0.0
4      9.4    1.9  3.51    0.0
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 6497 entries, 0 to 6496
Data columns (total 4 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   alcohol  6497 non-null   float64
 1   sugar    6497 non-null   float64
 2   pH       6497 non-null   float64
 3   class    6497 non-null   float64
dtypes: float64(4)
memory usage: 203.2 KB
</code></pre>
  <div id="df-48528a69-cb29-4de8-87e8-3cfa8e7538c1">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alcohol</th>
      <th>sugar</th>
      <th>pH</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
      <td>6497.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>10.491801</td>
      <td>5.443235</td>
      <td>3.218501</td>
      <td>0.753886</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.192712</td>
      <td>4.757804</td>
      <td>0.160787</td>
      <td>0.430779</td>
    </tr>
    <tr>
      <th>min</th>
      <td>8.000000</td>
      <td>0.600000</td>
      <td>2.720000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>9.500000</td>
      <td>1.800000</td>
      <td>3.110000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10.300000</td>
      <td>3.000000</td>
      <td>3.210000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>11.300000</td>
      <td>8.100000</td>
      <td>3.320000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>14.900000</td>
      <td>65.800000</td>
      <td>4.010000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-48528a69-cb29-4de8-87e8-3cfa8e7538c1')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-48528a69-cb29-4de8-87e8-3cfa8e7538c1 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-48528a69-cb29-4de8-87e8-3cfa8e7538c1&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<ul>
<li>데이터 가공</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련데이터 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size = <span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((5197, 3), (1300, 3), (5197,), (1300,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr= LogisticRegression()</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.7808350971714451
0.7776923076923077
</code></pre>
<ul>
<li>모델 만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.core.common <span class="keyword">import</span> random_state</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeClassifier(criterion = <span class="string">&#x27;entropy&#x27;</span>, max_depth = <span class="number">8</span>, random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>0.89532422551472
0.8569230769230769
</code></pre>
<p><img src="/images/0704/output_28_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/0704/output_29_0.png" alt="png"></p>
<h3 id="노드란-무엇인가"><a href="#노드란-무엇인가" class="headerlink" title="노드란 무엇인가?"></a>노드란 무엇인가?</h3><ul>
<li>0 이면 레드와인</li>
<li>1 이면 화이트와인 : 4898</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_target</span><br></pre></td></tr></table></figure>




<pre><code>array([1., 0., 0., ..., 1., 1., 0.])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt, max_depth=<span class="number">1</span>,</span><br><span class="line">          filled=<span class="literal">True</span>,</span><br><span class="line">          feature_names=[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 루트노드 - 뿌리노드, 노드, 리트노드</span></span><br></pre></td></tr></table></figure>


<p><img src="/images/0704/output_32_0.png" alt="png"></p>
<ul>
<li>불순도<ul>
<li>비율</li>
<li>레드와인 5:5 화이트와인</li>
<li>한 범주 안에서 서로 다른 데이터가 얼마나 섞여 있는지 나타냄<ul>
<li>흰색과 검은색이 각각 50개 섞여 있다<ul>
<li>불순도 최대 - 0.5</li>
</ul>
</li>
<li>흰색과 검은색이 완전 100% 분리<ul>
<li>흰색 노드 불순도 최소 - 0</li>
<li>검은색 노드 불순도 최소 - 0</li>
</ul>
</li>
</ul>
</li>
<li>엔드로피<ul>
<li>불확실한 정도를 의미 0-1사이</li>
<li>흰색과 검은색이 각각 50개 섞여 있다<ul>
<li>엔트로피 최대 -1</li>
</ul>
</li>
</ul>
</li>
<li>흰색과 검은색이 완전 100% 분리됨<ul>
<li>흰색 노드 엔트로피 최소 -0</li>
<li>검은색 노드 엔트로피 최소 - 0</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="특성-중요도"><a href="#특성-중요도" class="headerlink" title="특성 중요도"></a>특성 중요도</h3><ul>
<li>어떤 특성이 결정 트리 모델에 영향을 주었는가?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(dt.feature_importances_)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[0.15533444 0.6675247  0.17714086]
</code></pre>
<h2 id="현업에서-적용"><a href="#현업에서-적용" class="headerlink" title="현업에서 적용"></a>현업에서 적용</h2><ul>
<li>현업에서 decisiontreeclassifier(70년대)</li>
<li>랜덤포레스트, xgboost 하이퍼파라미터 매우 많음</li>
<li></li>
</ul>
<h2 id="검증-세트"><a href="#검증-세트" class="headerlink" title="검증 세트"></a>검증 세트</h2><ul>
<li>훈련세트와 테스트세트</li>
<li>훈련 : 교과서 공부하는 것, 훈련세트<br>모의평가</li>
<li>검증 : 강남대성 모의고사 문제집</li>
<li>테스트 : 6월 &#x2F; 9월</li>
<li>실전 : 수능</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;http://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line"><span class="comment"># print(wine.head())</span></span><br><span class="line"></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 훈련 80% 테스트 20%</span></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size = <span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<pre><code>((5197, 3), (1300, 3), (5197,), (1300,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 훈련 80% 검증 20%</span></span><br><span class="line">sub_input,val_input, sub_target, val_target = train_test_split(</span><br><span class="line">    train_input, train_target, test_size = <span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">sub_input.shape,val_input.shape, sub_target.shape, val_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((4157, 3), (1040, 3), (4157,), (1040,))
</code></pre>
<ul>
<li>훈련데이터 :train(x) sub_input, target이 훈련 데이터</li>
<li>검증데이터 - val_input, val_target</li>
<li>테스트데이터 - test_input,test_target</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모형 만들기</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(sub_input, sub_target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;훈련성과 : &quot;</span>, dt.score(sub_input, sub_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;검증성과:&quot;</span>, dt.score(val_input, val_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;마지막 최종 :&quot;</span>, dt.score(test_input,test_target))</span><br></pre></td></tr></table></figure>

<pre><code>훈련성과 :  0.9971133028626413
검증성과: 0.864423076923077
마지막 최종 : 0.8569230769230769
</code></pre>
<ul>
<li>훈련 : 87%</li>
<li>검증 : 86%</li>
</ul>
<hr>
<ul>
<li>최종 : 55%</li>
</ul>
<h3 id="교차검증"><a href="#교차검증" class="headerlink" title="교차검증"></a>교차검증</h3><ul>
<li>각 데이터 셋을 반복 분할</li>
<li>FOR LOOP</li>
<li>샘플링 편향적일 수 있음</li>
<li>교차 검증을 한다고 해서, 정확도가 무조건 올라가는 건 아님<ul>
<li>모형을 안정적으로 만들어 줘야함<ul>
<li>과대적합 방지</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line">df = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>])</span><br><span class="line"><span class="comment"># 데이터 K 폴드로 나눈다.</span></span><br><span class="line">folds = KFold(n_splits = <span class="number">5</span>, shuffle = <span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx, valid_idx <span class="keyword">in</span> folds.split(df):</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&#x27;훈련 데이터 : <span class="subst">&#123;df[train_idx]&#125;</span>, 검증데이터: <span class="subst">&#123;df[valid_idx]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>훈련 데이터 : [ 1  2  3  4  5  7  8 10], 검증데이터: [6 9]
훈련 데이터 : [ 1  3  5  6  7  8  9 10], 검증데이터: [2 4]
훈련 데이터 : [ 2  3  4  6  7  8  9 10], 검증데이터: [1 5]
훈련 데이터 : [ 1  2  3  4  5  6  9 10], 검증데이터: [7 8]
훈련 데이터 : [1 2 4 5 6 7 8 9], 검증데이터: [ 3 10]
</code></pre>
<ul>
<li>교차 검증 함수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores = cross_validate(dt, train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균 : &quot;</span>, np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.03095126, 0.0305624 , 0.03208995, 0.03173757, 0.01049256]), &#39;score_time&#39;: array([0.00121951, 0.01135445, 0.0013237 , 0.00117183, 0.00115395]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125;
평균 :  0.855300214703487
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">scores = cross_validate(dt, train_input, train_target, cv = StratifiedKFold())</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.855300214703487
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">splitter = StratifiedKFold(n_splits=<span class="number">10</span>,shuffle=<span class="literal">True</span>,random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(dt, train_input, train_target,cv = splitter)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8574181117533719
</code></pre>
<h2 id="하이퍼-파라미터-튜닝"><a href="#하이퍼-파라미터-튜닝" class="headerlink" title="하이퍼 파라미터 튜닝"></a>하이퍼 파라미터 튜닝</h2><ul>
<li>그리드 서치<ul>
<li>사람이 수동적으로 입력</li>
<li>max_depth : [1,3,7]</li>
</ul>
</li>
<li>랜덤 서치<ul>
<li>사람이 범위만 지정</li>
<li>max_depth: 1-10&#x2F; by random</li>
</ul>
</li>
<li>베이지안 옵티마이제이션</li>
<li>사람의 개입 없이 하이퍼파라미터 튜닝을 자동으로 수행하는 기술을 AutoML이라 함<ul>
<li>pycaret</li>
</ul>
</li>
<li>각 모델마다 적게는 1-2개에서, 많게는 5-6 개의 매개변수를 제공한다.<ul>
<li>xgboost 100개..?</li>
</ul>
</li>
<li>하이퍼파라미터와 동시에 교차 검증을 수행</li>
</ul>
<p>-교차검증 5번<br>교차검증 1번 돌때, max depth 3번 적용</p>
<ul>
<li>max dept &#x3D; 1,3,7<br> -총 결과값 15번 3 x 5 나옴</li>
<li>criterion &#x3D; gini, entropy</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params= &#123;</span><br><span class="line">    <span class="string">&#x27;criterion&#x27;</span> : [<span class="string">&#x27;gini&#x27;</span>,<span class="string">&#x27;entropy&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">7</span>],</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span>:[<span class="number">0.0001</span>,<span class="number">0.0002</span>,<span class="number">0.0003</span>,<span class="number">0.0004</span>,<span class="number">0.0005</span>]</span><br><span class="line">&#125;</span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state=<span class="number">42</span>), params, n_jobs=-<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input,train_target)</span><br></pre></td></tr></table></figure>




<pre><code>GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,
             param_grid=&#123;&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;],
                         &#39;max_depth&#39;: [1, 3, 7],
                         &#39;min_impurity_decrease&#39;: [0.0001, 0.0002, 0.0003,
                                                   0.0004, 0.0005]&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best:&quot;</span> , gs.best_estimator_)</span><br><span class="line">df=gs.best_estimator_</span><br></pre></td></tr></table></figure>

<pre><code>best: DecisionTreeClassifier(max_depth=7, min_impurity_decrease=0.0005,
                       random_state=42)
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kimsunhyung.github.io/2022/07/04/0704/" data-id="cl56glafj00002stv098kgp67" data-title="0704" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/07/05/0705pycaret_sample/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          0705pycaret_sample
        
      </div>
    </a>
  
  
    <a href="/2022/07/01/0701chap3/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">0701chap3</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/08/02/0802webserver/">0802webserver만들기</a>
          </li>
        
          <li>
            <a href="/2022/08/01/0801heroku%EB%B0%B0%ED%8F%AC/">0801heroku배포</a>
          </li>
        
          <li>
            <a href="/2022/07/29/0729%20pyspark_postgreSQL/">0729_pyspark_postgreSQL</a>
          </li>
        
          <li>
            <a href="/2022/07/28/0728airflow_pipeline_spark_install/">0728_airflow pipeline 구축 및 spark 설치</a>
          </li>
        
          <li>
            <a href="/2022/07/27/0727_WSL2%EC%84%A4%EC%B9%98_WINDOW%20SUBSYSTEM%20FOR%20linux%EC%84%A4%EC%B9%98/">0727 WSL2 설치</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>